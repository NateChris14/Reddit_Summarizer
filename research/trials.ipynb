{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d52bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.54)\n",
      "Requirement already satisfied: pandas in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sumy) (2.31.0)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nltk>=3.0.2 (from sumy)\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sqlalchemy) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Collecting chardet (from breadability>=0.1.20->sumy)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from breadability>=0.1.20->sumy) (5.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.0.2->sumy) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n",
      "Collecting tqdm (from nltk>=3.0.2->sumy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.7.0->sumy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.7.0->sumy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.7.0->sumy) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nathan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/6.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: docopt, breadability\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13822 sha256=fd5bde41178399ae884100866e44289190a5b1b651fc818f238209ef11758e5e\n",
      "  Stored in directory: c:\\users\\nathan\\appdata\\local\\pip\\cache\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21800 sha256=92f917042e31af3f8cfe629e35018648141380add793c3626a45b9c580124a57\n",
      "  Stored in directory: c:\\users\\nathan\\appdata\\local\\pip\\cache\\wheels\\4d\\57\\58\\7e3d7fedf51fe248b7fcee3df6945ae28638e22cddf01eb92b\n",
      "Successfully built docopt breadability\n",
      "Installing collected packages: docopt, tqdm, pycountry, chardet, nltk, breadability, sumy\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [tqdm]\n",
      "   ----- ---------------------------------- 1/7 [tqdm]\n",
      "   ----- ---------------------------------- 1/7 [tqdm]\n",
      "   ----------- ---------------------------- 2/7 [pycountry]\n",
      "   ----------- ---------------------------- 2/7 [pycountry]\n",
      "   ----------- ---------------------------- 2/7 [pycountry]\n",
      "   ----------------- ---------------------- 3/7 [chardet]\n",
      "   ----------------- ---------------------- 3/7 [chardet]\n",
      "   ----------------- ---------------------- 3/7 [chardet]\n",
      "   ----------------- ---------------------- 3/7 [chardet]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------- ----------------- 4/7 [nltk]\n",
      "   ---------------------------- ----------- 5/7 [breadability]\n",
      "   ---------------------------- ----------- 5/7 [breadability]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------- ----- 6/7 [sumy]\n",
      "   ---------------------------------------- 7/7 [sumy]\n",
      "\n",
      "Successfully installed breadability-0.1.20 chardet-5.2.0 docopt-0.6.2 nltk-3.9.2 pycountry-24.6.1 sumy-0.11.0 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'breadability' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'breadability'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\NATHAN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install sumy psycopg2-binary sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65209b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420be88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to local Postgres\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:postgres@localhost:5432/postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025f43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring the Summary table exists\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Summary(\n",
    "    summary_id SERIAL PRIMARY KEY,\n",
    "    post_id VARCHAR REFERENCES Posts(post_id),\n",
    "    summary_text TEXT,\n",
    "    model_used VARCHAR,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bddba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1q7rd9o</td>\n",
       "      <td>[P] Automated Code Comment Quality Assessment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1q7f7tr</td>\n",
       "      <td>[P] Three-Phase Self-Inclusive Evaluation Prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1q7aeoy</td>\n",
       "      <td>[R] Collecting memes for LLM study—submit your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1q72bd8</td>\n",
       "      <td>[D] I summarized my 4-year PhD on Geometric De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1q6y7di</td>\n",
       "      <td>[R] ALYCON: A framework for detecting phase tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                          full_text\n",
       "0  1q7rd9o  [P] Automated Code Comment Quality Assessment ...\n",
       "1  1q7f7tr  [P] Three-Phase Self-Inclusive Evaluation Prot...\n",
       "2  1q7aeoy  [R] Collecting memes for LLM study—submit your...\n",
       "3  1q72bd8  [D] I summarized my 4-year PhD on Geometric De...\n",
       "4  1q6y7di  [R] ALYCON: A framework for detecting phase tr..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch posts needing summary\n",
    "sql = \"\"\"\n",
    "SELECT p.post_id, p.full_text\n",
    "FROM Posts p\n",
    "WHERE NOT EXISTS (\n",
    "SELECT 1\n",
    "FROM Summary s\n",
    "WHERE s.post_id = p.post_id);\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(sql))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad32a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im documenting an ongoing series of reproducible experiments (this is 3 out of 100) exploring evaluation methodologies for small finetuned models in targeted synthetic data generation tasks. The setup is fully opensource (MIT license) with raw generations, individual analyses, and final aggregation available here: [ The goal is not to claim superiority but to investigate potential biases in LLMasjudge setups, tradeoffs in niche finetuning, and reproducibility of subjective evaluations. Id value feedback on: Methodological strengthsweaknesses (e.g., proprietary prompt limitations, selfranking biases) Suggestions for more rigorous aggregation or statistical analysis Ideas for extending the protocol in future iterations Looking forward to your thoughts on similar evaluation approaches or experiences with smallmodel finetuning tradeoffs.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize\n",
    "summarizer = TextRankSummarizer()\n",
    "summaries = []\n",
    "\n",
    "for row in df.to_dict(\"records\"):\n",
    "    post_id = row['post_id']\n",
    "    text_content = row['full_text']\n",
    "\n",
    "    parser = PlaintextParser.from_string(text_content, Tokenizer(\"english\"))\n",
    "    picked = summarizer(parser.document, 3) # 3 sentences\n",
    "\n",
    "    summaries.append({\n",
    "        \"post_id\": post_id,\n",
    "        \"summary_text\": \" \".join(str(s) for s in picked),\n",
    "        \"model_used\": \"sumy_textrank_3sent\"\n",
    "    })\n",
    "\n",
    "summ_df = pd.DataFrame(summaries)\n",
    "summ_df['summary_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84ef81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
